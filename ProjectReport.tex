\documentclass{article}

\usepackage{full page}
\usepackage{pdfpages}
\usepackage{graphicx}
\usepackage{float}
\usepackage{mdframed}
\usepackage{minted}
\usepackage{enumerate}


\usepackage{listings}
\lstset{language=Python}

\title{Profile Hidden Markov Models}
\author{Taylor Cathcart, Cam Setian, Kyle Tessier-Lavigne}

\begin{document}
\maketitle

\section{Introduction}

As the cost of genetic sequencing has dropped significantly over the past decade, there has become an abundance of unprocessed genetic data. Many different computational methods have been developed or adapted to look for patterns in sets of genetic sequences, including Hidden Markov Models, which are particularly useful for processing signals from noise. One of the first applications of HMMs was in speech recognition in the 70s, and since then, many uses have been found in biological sequence analysis, including gene prediction, sequence alignment, structural alignment, and more.\footnotemark[1] When we talk about problems concerning HMMs, we usually mean one of three things:
\begin{enumerate}
\item Evaluation: What is the probability that a particular sequence of emissions is the output of a HMM model?
\item Decoding: Given a sequence of emissions and a model, what is the most likely sequence of states that emitted the given sequence?
\item Training: Given a set of sequences and a model, find a model that best fits the emission sequences.
\end{enumerate}
In this report, we begin by attempting to train a model and then move on to solve the evaluation problem. We can then use this to create models based on families of sequences and cross-validate our model, as well as potentially use it to identify other sequences in the family.

\footnotetext[1]{Hidden Markov Models and their Applications in Biological Sequence Analysis. Current Genomics. Sep 2009; 10(6): 402-415}

\section{Hidden Markov Models}

A Hidden Markov Model describes the probabilistic relationship between a set of hidden (i.e. unobservable) states and a set of known observations. If one knows the probability of going from one state to another at each time interval (the transition probability), and the probability that a given observation will be expressed by each state (the emission probability), then given a sequence of observations, one should be able to use this model to predict the most likely sequence of states corresponding to those observations. For example, say two people, Ann and Bob, live far apart. Bob tells Ann what he did each day for a week. Ann, who lives far from Bob, doesn't know what the weather is like for Bob each day. However, Ann does know the probability that Bob will do a certain activity based on the weather where he lives. She also knows the probability that a rainy day will be followed by a sunny day, and vice-versa. Using this information (where the weather reprsents the unobservable state, and the activity represents the observation for that day), Ann should be able to figure out the most likely weather pattern for that week.
\begin{figure}[H]
\centering
\includegraphics[width=.5\textwidth]{materials/HMMGraph.png}
\caption{Transition probabilities between states, and their emission probabilities for each observation\footnotemark[2]}
\end{figure}

\footnotetext[2]{http://en.wikipedia.org/wiki/File:HMMGraph.svg}

\section{Profile-Hidden Markov Models}

Profile-Hidden Markov Models are an adaptation of HMMs used to model genetic sequences. A profile-HMM consists of a sequence of match, insert, and delete states which span the length of the consensus sequence. A match corresponds to the expression of either a nucleotide (in the case of DNA sequencing) or an amino acid (in the case of protein sequencing). Insert and delete states correspond to the expression of a gap. 
\begin{figure}[H]
\centering
\includegraphics[width=.8\textwidth]{materials/profile-HMM.png}
\caption{profile-HMM\footnotemark[1]}
\end{figure}
Each position in the sequence is represented by one match state, one insert state, and one delete state. Aside from the insert states, a state may only transition to another state that is in the next sequential step in the sequence. Thus each position in the sequence (1 \ldots k) can be represented as $M_{1} I_{1} D_{1}, M_{2} I_{2} D_{2} \ldots M_{k} I_{k} D_{k}$. The probabilities of each state transitioning to each other valid state describes the set of transition probabilities for the model. Each match state contains a probability distribution for the alphabet of amino acids, describing the set of emission probabilities for that state.

\section{Methods}


\subsection{profile-HMM implementation}
The profile-HMM is first initialized with a start and end node (which do not correspond to the sequence itself), as well as transition probabilities using a pseudocount of 1 for each weight (scaled for insertions and deletions to 0.2). The actual profile itself is constructed in the ProfileHMM class

\subsection{Viterbi Scoring Algorithm}


\section{Application}
To test our profile-HMM, we used two different gene families taken from pfam, Cancer-associated gene protein 1 (CAGE1)\footnotemark[3] and Oesophageal cancer-related gene 4 (Augurin).\footnotemark[4] Using the smaller seed alignments for each family, which pfam used to assemble the family as a whole, we trained two separate models (one for each family). We then compared our models to both their own sets and the opposite sets to confirm that our model was getting higher probability scores for its own family.

In order to compare against more established methods, we built HMMs on the same seed multiple sequence alignments using HMMer, then ran a search on pfam's database using those HMMs. 

\footnotetext[3]{http://pfam.xfam.org/family/PF15066}
\footnotetext[4]{http://pfam.xfam.org/family/PF15187}

\section{Results}
didn't work because of underflow - rounding floating point errors caused it to be reduced to 0

if we had more time, use a log likelihood transform 

\section{Discussion}


% Example for formatting code:
% 
% \begin{minted}[mathescape, linenos, numbersep=3pt, gobble=0, framesep=20mm]{python}
% 
% if __name__ == '__main__':
% 	print 'hello world'
% 
% \end{minted}



% Example for inserting figures:
% 
% \begin{figure}[H]
% \centering
% \includegraphics[width=.5\textwidth]{filename goes here}
% \caption{\bf caption goes here}
% \end{figure}


\end{document}